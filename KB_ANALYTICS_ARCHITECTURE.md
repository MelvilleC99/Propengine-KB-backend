# KB Analytics Architecture - FIXED

## ‚úÖ **WHAT WAS FIXED**

### **Problem 1: Missing entry_id from Sources** ‚úÖ
**File**: `/src/query/vector_search.py`

**Before**:
```python
result = {
    "content": doc.content,
    "metadata": doc.metadata,
    # ‚ùå NO entry_id!
}
```

**After**:
```python
result = {
    "entry_id": doc.id or doc.metadata.get('_id'),  # ‚úÖ Actual AstraDB document ID
    "content": doc.content,
    "metadata": doc.metadata,
}
```

---

### **Problem 2: KB Usage Tracker Using Wrong Collection** ‚úÖ
**File**: `/src/memory/kb_analytics.py`

**Changes**:
1. Renamed class to `KBStatsTracker` (kept old name as alias for compatibility)
2. Changed collection from `kb_analytics` ‚Üí `kb_stats`
3. Now uses actual `entry_id` from source instead of normalized title
4. Falls back to normalized title only if `entry_id` is missing

**Before**:
```python
self.analytics_collection = "kb_analytics"  # ‚ùå Wrong collection
entry_id = self._normalize_entry_id(title)  # ‚ùå Using normalized title
```

**After**:
```python
self.stats_collection = "kb_stats"  # ‚úÖ Correct collection
entry_id = source.get("entry_id")   # ‚úÖ Using actual AstraDB ID
```

---

### **Problem 3: Batch Analytics Not Storing KB Entries** ‚úÖ
**File**: `/src/database/firebase_analytics_service.py`

**Added**:
```python
# Extract and format KB entries used
kb_entries_used = []
for source in sources_used:
    entry_info = {
        "entry_id": source.get("entry_id"),  # ‚úÖ Actual ID
        "entry_title": source.get("title"),
        "entry_type": source.get("entry_type"),
        "similarity_score": source.get("similarity_score")
    }
    kb_entries_used.append(entry_info)

analytics_doc = {
    "query_id": query_ref.id,  # ‚úÖ Auto-generated
    "kb_entries_used": kb_entries_used,  # ‚úÖ Array of entries
    ...
}
```

---

## üìä **FINAL ARCHITECTURE**

### **Collection 1: kb_analytics** (Individual Query Records)
**Purpose**: Track each query individually  
**Write Type**: BATCH (at session end)  
**Document ID**: Auto-generated by Firestore

```json
{
  "query_id": "auto_generated_abc123",
  "session_id": "session_xyz",
  "agent_id": "PlTZWNC6...",
  "query_text": "how do I create a sale",
  "timestamp": "2026-01-28...",
  
  "kb_entries_used": [
    {
      "entry_id": "create_sale_howto_123",
      "entry_title": "How to Create a Sale",
      "entry_type": "how_to",
      "similarity_score": 0.89
    },
    {
      "entry_id": "sale_workflow_456",
      "entry_title": "Sale Workflow",
      "entry_type": "workflow",
      "similarity_score": 0.82
    }
  ],
  
  "confidence_score": 0.85,
  "escalated": false,
  "user_feedback": null
}
```

---

### **Collection 2: kb_stats** (KB Entry Performance)
**Purpose**: Aggregate statistics per KB entry  
**Write Type**: INSTANT (on each query)  
**Document ID**: Actual entry_id from AstraDB/Pinecone

```json
{
  "entry_id": "create_sale_howto_123",
  "entry_title": "How to Create a Sale",
  "entry_type": "how_to",
  
  "usage_count": 21,
  "avg_confidence": 0.869,
  "avg_similarity_score": 0.834,
  
  "first_used": "2026-01-26...",
  "last_used": "2026-01-28...",
  "last_query": "how do I create a sale",
  "last_session_id": "session_xyz"
}
```

---

## üîÑ **DATA FLOW**

### **During Query** (Real-time)
```
1. User sends query
2. Vector search returns results with entry_id
3. kb_stats tracker updates INSTANTLY (Firebase write)
   ‚Üí Increments usage_count
   ‚Üí Recalculates averages
   ‚Üí Updates last_used
4. Query metadata buffered in memory
```

### **At Session End** (Batch)
```
1. Session ends
2. Buffer contains all query metadata
3. Batch write to kb_analytics (individual query records)
   ‚Üí Each query gets own document
   ‚Üí Includes array of kb_entries_used
4. Write session summary to kb_sessions
5. Update user stats in users collection
```

---

## üìÅ **FILES MODIFIED**

1. ‚úÖ `/src/query/vector_search.py` - Added entry_id extraction
2. ‚úÖ `/src/memory/kb_analytics.py` - Renamed to use kb_stats collection
3. ‚úÖ `/src/database/firebase_analytics_service.py` - Added kb_entries_used array

---

## üéØ **KEY BENEFITS**

### **kb_analytics Collection**
- ‚úÖ Each query has unique auto-generated ID
- ‚úÖ Links to specific KB entries used via entry_id
- ‚úÖ Can track which entries were used together
- ‚úÖ Can analyze user feedback per query
- ‚úÖ Can trace back to session and user

### **kb_stats Collection**
- ‚úÖ Uses actual AstraDB document ID (not normalized title)
- ‚úÖ Real-time visibility into KB performance
- ‚úÖ Easy to query "most used entries"
- ‚úÖ Track confidence trends per entry
- ‚úÖ Identify low-performing entries

---

## üîó **LINKING DATA**

### **From Query to KB Entries**:
```python
# Get query from kb_analytics
query = db.collection("kb_analytics").document("query_abc123").get()

# Get each KB entry used
for entry in query["kb_entries_used"]:
    entry_stats = db.collection("kb_stats").document(entry["entry_id"]).get()
    print(f"{entry_stats['entry_title']}: {entry_stats['usage_count']} uses")
```

### **From KB Entry to Queries**:
```python
# Get all queries that used this entry
entry_id = "create_sale_howto_123"
queries = db.collection("kb_analytics") \
    .where("kb_entries_used", "array_contains", {"entry_id": entry_id}) \
    .get()
```

---

## ‚úÖ **TESTING**

### **To Verify It Works**:

1. **Make a query** through any agent endpoint
2. **Check kb_stats** collection:
   ```
   Document ID: {actual_entry_id_from_astradb}
   Should have: entry_id, usage_count, avg_confidence
   ```
3. **End the session** (wait 30min or call /sessions/end)
4. **Check kb_analytics** collection:
   ```
   Document ID: {auto_generated}
   Should have: query_id, kb_entries_used array with entry_ids
   ```

---

## üö® **BACKWARDS COMPATIBILITY**

- Old `KBAnalyticsTracker` class name still works (alias to `KBStatsTracker`)
- Falls back to normalized title if `entry_id` is missing
- Existing code importing `KBAnalyticsTracker` will continue to work

---

**All KB analytics issues are now fixed!** ‚úÖ
